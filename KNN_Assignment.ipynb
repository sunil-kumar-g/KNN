{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\tExplain the working of KNN algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN is an supervised machine learning algorithm. It works well with both Regressiong and Classification problems. It tries to \n",
    "predict the correct class of test data by calculating the distance between the Test data and the trained data. Based on the k-value\n",
    "selected, it selects that many points closest to the Test data. Once selected, the algorithm calculates the probability of test\n",
    "point and the highest probablity gets selected to class A or Class B in case of binary classification problem. \n",
    "In case of the regression problem, the predicted value is the mean of the k selected training points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\tHow KNN predicts the output for regression and classification problems?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN algorithm calculates the distance between the test data and the training data. As per the k values selected, it selects the \n",
    "training points near the test data example, if k=3 then it will select 3 nearest training data points to the test data and selects\n",
    "that class to which it has highest probability. In case of Regression problem , it predicts the value by simply taking the mean of the \n",
    "3 nearest values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\tWhat are the different distances used in KNN? How are they calculated?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Euclidean distance : it calculates the distance between the two points\n",
    "2. Hamming Distance : It is a distance metric that measures the number of mismatches between two vectors.\n",
    "3. Manhattan Distance: This distance represents the sum of the absolute differences between the opposite values in vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)\tWhat are Lazy Learners? Why KNN is called a lazy learner?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lazy learner doesnt not genearlize the model with the training data available but waits for the test data. Similarly KNN algorithm\n",
    "also doesnt genearlize the model for the training set but waits for the test data. Once the test data is provided then only it \n",
    "starts generlizeing the training data to classify the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)\tHow do we select the value of k? How bias and variance varies with k?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We use different ways to calculate the optimum k value such as cross validation, error versus k curve, checking accuracy for \n",
    "each value of k.\n",
    "With lower value of ‘k’ variance is high and bias is low but as we increase the value of ‘k’ variance starts decreasing and \n",
    "bias starts increasing. With very low values of ‘k’ there is a chance of algorithm overfitting the data whereas with very high \n",
    "value of ‘k’ there is a chance of underfitting.\n",
    "Hence we need to come to a right trade off between train error rate and test error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)\tWhat are advantages and disadvantages of KNN?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantages:\n",
    "It can be used for both regression and classification problems.\n",
    "It is very simple and easy to implement.\n",
    "There is no need to create model or do hyperparameter tuning.\n",
    "Mathematics behind the algorithm is easy to understand.\n",
    "\n",
    "Finding the optimum value of ‘k’\n",
    "It takes a lot of time to compute the distance between each test sample and all training samples.\n",
    "Since the model is not saved beforehand in this algorithm (lazy learner), so every time one predicts a test value, it follows\n",
    "the same steps again and again. \n",
    "Since, we need to store the whole training set for every test set, it requires a lot of space.\n",
    "It is not suitable for high dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7)\tDiscuss kDTree algorithm used for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k-d tree is a hierarchical binary tree. When this algorithm is used for k-NN classficaition, it rearranges the whole dataset in\n",
    "a binary tree structure, so that when test data is provided, it would give out the result by traversing through the tree, which \n",
    "takes less time than brute search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "8)\tDiscuss Ball Tree algorithm used for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ball trees are hierarchical data structure. These are very efficient specially in case of higher dimensions.\n",
    "These are formed by following steps:\n",
    "Two clusters are created initially.\n",
    "All the data points must belong to atleast one of the clusters.\n",
    "One point cannot be in both clusters.\n",
    "Distance of the point is calculated from the centroid of the each cluster. The point closer to the centroid goes into that particular cluster.\n",
    "Each cluster is then divided into sub clusters again, and then the points are classified into each cluster on the basis of distance from centroid.\n",
    "This is how the clusters are kept to be divided till a certain depth.\n",
    "Ball tree formation initially takes a lot of time but once the nested clusters are created, finding nearest neighbors is easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
